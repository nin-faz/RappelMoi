import Foundation
import AVFoundation
import Speech
import Combine

// Wrapper pour g√©rer les alertes avec Identifiable
struct AlertWrapper: Identifiable {
    let id = UUID()
    let message: String
}

var audioPlayer: AVAudioPlayer?

// Classe qui g√®re la synth√®se vocale et la reconnaissance vocale
class SpeechManager: NSObject, ObservableObject, AVSpeechSynthesizerDelegate {

    // Variables observables pour informer la vue (ContentView) des changements
    @Published var recognizedText = ""   // Texte reconnu par la reconnaissance vocale
    @Published var isRecording = false   // Est-ce que l'enregistrement est en cours ?
    @Published var isSpeaking = false    // Est-ce que la synth√®se vocale parle ?
    @Published var alertMessage: AlertWrapper? // Message d'alerte √† afficher en cas d'erreur ou probl√®me
    @Published var readyToListen = false // Pour enregistrer notre voix juste apr√®s le son d'activation vocale
    @Published var reminders: [Reminder] = [] // Liste observable de rappels que l'on va afficher dans l'UI
    
    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "fr-FR")) // Reconnaissance vocale FR
    private let audioEngine = AVAudioEngine() // G√®re l'entr√©e audio du micro
    private var request = SFSpeechAudioBufferRecognitionRequest() // Objet pour envoyer les donn√©es audio √† Apple
    private var recognitionTask: SFSpeechRecognitionTask? // T√¢che de reconnaissance en cours
    private var speechSynthesizer = AVSpeechSynthesizer() // Pour parler avec la voix synth√©tique
    
    private var silenceTimer: Timer? // Timer pour d√©tecter le silence prolong√©
    
    // Initialisation : on met ce SpeechManager en tant que d√©l√©gu√© pour la synth√®se vocale
    override init() {
        super.init()
        speechSynthesizer.delegate = self
    }
    
    // Fonction pour jouer un son de d√©marrage (notif-activation-vocale.mp3)
    func playSoundThenStartRecording() {
        readyToListen = false // On est pas encore pr√™t
        guard let soundURL = Bundle.main.url(forResource: "notif-activation-vocale", withExtension: "mp3") else {
            print("üîá Son introuvable")
            return
        }
        do {
            try AVAudioSession.sharedInstance().setCategory(.playback, mode: .default)
            try AVAudioSession.sharedInstance().setActive(true)
            audioPlayer = try AVAudioPlayer(contentsOf: soundURL)
            audioPlayer?.delegate = self
            audioPlayer?.play()
        } catch {
            print("Erreur de lecture du son : \(error.localizedDescription)")
        }
    }
    
    // Demande d'autorisation pour acc√©der au micro et √† la reconnaissance vocale
    func requestPermissionAndRecord() {
        SFSpeechRecognizer.requestAuthorization { authStatus in
            DispatchQueue.main.async {
                if authStatus == .authorized {
                    self.startRecording()  // Autoris√© : on commence √† √©couter
                } else {
                    self.alertMessage = AlertWrapper(message: "Autorisation refus√©e pour la reconnaissance vocale.")
                }
            }
        }
    }
    
    // D√©marre l'enregistrement audio et lance la reconnaissance vocale
    func startRecording() {
        recognizedText = ""  // R√©initialise le texte reconnu
        isRecording = true   // Indique que l'enregistrement est actif
        
        let audioSession = AVAudioSession.sharedInstance()
        do {
            try audioSession.setCategory(.record, mode: .measurement, options: .duckOthers)
            try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
        } catch {
            alertMessage = AlertWrapper(message: "Erreur de session audio : \(error.localizedDescription)")
            isRecording = false
            return
        }
        
        let inputNode = audioEngine.inputNode
        
        audioEngine.prepare()
        do {
            try audioEngine.start()
        } catch {
            alertMessage = AlertWrapper(message: "Erreur lors du d√©marrage de l'audio.")
            isRecording = false
            return
        }
        
        let inputFormat = inputNode.inputFormat(forBus: 0)
//        print("Input format: \(inputFormat)")

        // Cr√©e une nouvelle requ√™te pour bufferiser l'audio
        request = SFSpeechAudioBufferRecognitionRequest()
        request.shouldReportPartialResults = true // Rapport des r√©sultats partiels (en temps r√©el)
        
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: inputFormat) { buffer, when in
            self.request.append(buffer)
        }
        

        // Lance la reconnaissance vocale avec la requ√™te
        recognitionTask = speechRecognizer?.recognitionTask(with: request) { result, error in
            if let result = result {
                self.recognizedText = result.bestTranscription.formattedString // Mets √† jour le texte reconnu
                
                // üîÅ R√©initialise le timer √† chaque mot reconnu
                self.startSilenceTimer()
            }
            
            // Si erreur ou fin de reconnaissance, on arr√™te l'enregistrement
            if error != nil || (result?.isFinal ?? false) {
                self.stopRecording()
            }
        }
        
        // üïí D√©marre le timer de silence d√®s le d√©but de l‚Äô√©coute
        startSilenceTimer()
    }
    
    // Arr√™te l'enregistrement et la reconnaissance vocale
    func stopRecording() {
        audioEngine.stop()
        audioEngine.inputNode.removeTap(onBus: 0)
        recognitionTask?.cancel()
        isRecording = false
        
        // üõë Arr√™te le timer de silence
        silenceTimer?.invalidate()
        silenceTimer = nil
    }
    
    // Lance ou relance le timer de silence de 3 secondes
    private func startSilenceTimer() {
        silenceTimer?.invalidate() // On annule l'ancien timer s'il existe
        silenceTimer = Timer.scheduledTimer(withTimeInterval: 3.0, repeats: false) { _ in
            print("‚è±Ô∏è Silence d√©tect√©, arr√™t de l'√©coute.")
            self.stopRecording()
        }
    }
    
    // Fonction pour que la machine parle avec la voix synth√©tique
    func speak(text: String) {
        if speechSynthesizer.isSpeaking {
            speechSynthesizer.stopSpeaking(at: .immediate) // Stop la parole pr√©c√©dente si besoin
        }
        
        let audioSession = AVAudioSession.sharedInstance()
        do {
            try audioSession.setCategory(.playback, mode: .default)
            try audioSession.setActive(true)
            
            // V√©rifie si le volume est √† z√©ro (silencieux)
            if audioSession.outputVolume == 0 {
                alertMessage = AlertWrapper(message: "Ton iPhone est en mode silencieux ou le volume est √† z√©ro, augmente le son.")
                return
            }
            
            let utterance = AVSpeechUtterance(string: text)
            utterance.voice = AVSpeechSynthesisVoice(language: "fr-FR")
            speechSynthesizer.speak(utterance) // Lance la synth√®se vocale
            isSpeaking = true
            
        } catch {
            alertMessage = AlertWrapper(message: "Erreur : \(error.localizedDescription)")
        }
    }
    
    // Fonction pour ajouter un nouveau rappel √† la liste
    func addReminder(text: String, date: Date) {
        guard date >= Date() else {
            alertMessage = AlertWrapper(message: "Impossible de mettre un rappel dans le pass√©.")
            return
        }
        let newReminder = Reminder(text: text, date: date)  // Cr√©e un rappel avec le texte et la date fournis
        reminders.append(newReminder) // Ajoute ce rappel √† la liste
    }
}

// AVSpeechSynthesizerDelegate
extension SpeechManager {
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didFinish utterance: AVSpeechUtterance) {
        isSpeaking = false
    }
}

// AVAudioPlayerDelegate
extension SpeechManager: AVAudioPlayerDelegate {
    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        readyToListen = true
        isRecording = true
        do {
            try AVAudioSession.sharedInstance().setCategory(.record, mode: .measurement, options: .duckOthers)
            try AVAudioSession.sharedInstance().setActive(true)
        } catch {
            print("Erreur remise session audio : \(error.localizedDescription)")
        }
        startRecording()
    }
}
